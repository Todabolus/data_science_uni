{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Modellierung: Regressions- und Klassifikationsmodelle auf Finanzdaten\n",
    "\n",
    "In diesem Notebook werden verschiedene Modelle auf einem Finanzdatensatz angewendet. Ziel ist es, sowohl Regressions- als auch Klassifikationsmodelle zu erstellen und zu evaluieren. Folgende Modelle werden betrachtet:\n",
    "\n",
    "- **Multiple Lineare Regression (MLR):** Vorhersage der absoluten Rendite (|Return|)\n",
    "\n",
    "- **Naive Bayes:** Klassifikation der Kursrichtung (steigend/fallend)\n",
    "\n",
    "- **Lineare Diskriminanzanalyse (LDA):** Klassifikation der Kursrichtung\n",
    "\n",
    "\n",
    "\n",
    "Das Notebook ist in mehrere Abschnitte gegliedert, die jeweils durch Markdown-Zellen erläutert werden."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "## **1. Abhängikeiten laden & Daten einlesen**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from utils.modeling.models import mlr, naive_bayes, lda, logistic_regression_classifier\n",
    "from utils.modeling.evaluation import evaluate_regression, evaluate_classification\n",
    "\n",
    "df = pd.read_csv('data/merged/merged_by_timestamp.csv')\n",
    "display(df.head())\n",
    "display(df.tail())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "Wichtige Uhrzeiten übernehmen\n",
    "\n",
    "## **2. Datenfilterung**\n",
    "\n",
    "Hier wird eine Maske erstellt welche die ```top_times```, die Top Uhrzeiten geflitert im [02_eda.ipynb](02_eda.ipynb), erschließt.\n",
    "\n",
    "Die Maske besteht aus folgendn Uhrzeiten:\n",
    "- 13:30:00\n",
    "- 15:00:00\n",
    "- 19:00:00\n",
    "\n",
    "Dadurch konzentrieren wir uns auf Zeitpunkte, an denen relevante Ereignisse im Datensatz vorliegen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_times = [\"13:30:00\", \"15:00:00\", \"19:00:00\"]\n",
    "\n",
    "mask_times   = df[\"Timestamp\"].str.endswith(tuple(top_times))\n",
    "mask_events  = df[\"event_count\"] > 0\n",
    "mask         = mask_times & mask_events\n",
    "\n",
    "display(df.loc[mask].head())\n",
    "display(df.loc[mask].tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "## **3. Feature-Engineering**\n",
    "Erstellt verschobene Features und berechnet prozentuale Preisänderungen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Volume_shifted\"]         = df[\"Volume\"].shift(1)\n",
    "df[\"|Return|_shifted1\"]      = df[\"|Return|\"].shift(1)\n",
    "df[\"|Close_pct_change_2h|\"]  = ((df[\"Close\"].shift(1) - df[\"Close\"].shift(5)) / df[\"Close\"].shift(5) * 100).abs()\n",
    "df[\"|Close_pct_change_4h|\"]  = ((df[\"Close\"].shift(1) - df[\"Close\"].shift(9)) / df[\"Close\"].shift(5) * 100).abs()\n",
    "\n",
    "\n",
    "mask &= df[\"Volume_shifted\"].notna()\n",
    "\n",
    "print(\"shape nach Maskierung:\", df.loc[mask].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "## **4. Zielvariablen und Features**\n",
    "Definiert die Targets und entfernt nicht benötigte Spalten.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Label\"] = (df[\"Return\"] >= 0).astype(int)\n",
    "\n",
    "drop_columns = [\n",
    "    \"Open\", \"High\", \"Low\", \"Close\",\n",
    "    \"Return\", \"|Return|\", \"Volume\",\n",
    "    \"Timestamp\", \"Label\"\n",
    "]\n",
    "\n",
    "X = df.loc[mask].drop(columns=drop_columns, errors=\"ignore\")\n",
    "print(\"Anzahl der Datenpunkte in X:\", len(X))\n",
    "\n",
    "y_regression     = df.loc[mask, \"|Return|\"].values\n",
    "y_classification = df.loc[mask, \"Label\"].values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "## **5. Regression mit Bootstrap-Intervallen**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1, X_tr, X_te, y_tr, y_te = mlr(\n",
    "    X, y_regression,\n",
    "    train_ratio=0.5,\n",
    "    random_state=42,\n",
    "    n_bootstrap=10_000,\n",
    "    ci=0.95\n",
    ")\n",
    "\n",
    "evaluate_regression(model1, X_tr, y_tr, X_te, y_te, n_last=50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "### Interpretation\n",
    "*Prognosemodell: absoluter, prozentualer 30-Min-Return nach News-Veröffentlichung*\n",
    "\n",
    "##### 1 ) Güte der Gesamt­gleichung  \n",
    "\n",
    "| Kennzahl | Train | Test | Interpretation |\n",
    "|----------|------:|-----:|----------------|\n",
    "| **R²**   | 0.269 | 0.258 | ≈ 26 % der Varianz wird erklärt – bei hoch­frequenten Finanz­daten beachtlich, aber das meiste bleibt Rauschen. |\n",
    "| **RMSE** | 0.208 | 0.206 | Fehler liegt in ähnlicher Größen­ordnung wie der mittlere Target-Wert. |\n",
    "| **MAE**  | 0.145 | 0.140 | Robustes Fehler­maß bestätigt RMSE-Befund. |\n",
    "| **Train vs. Test** | – | – | Fast identische Ergebnisse ⇒ kaum Overfitting; lineares Modell stößt schlicht an Grenzen. |\n",
    "\n",
    "\n",
    "##### 2 ) Bedeutung der Koeffizienten (Bootstrap-CIs)  \n",
    "\n",
    "| Feature (Auswahl) | β | 95 %-CI | Deutung |\n",
    "|-------------------|---:|:-------:|---------|\n",
    "| `\\|Return\\|_shifted1` | **0.25** | [+0.17; +0.35] | Volatility-Clustering: vergangene Schwankung setzt sich fort. |\n",
    "| `cat_interest_rate_impact_max` | **0.03** | [+0.01; +0.05] | Zins-Schlagzeilen erhöhen Volatilität signifikant. |\n",
    "| `cat_labor_market_impact_max` | **-0.03** | [-0.04; -0.01] | Arbeitsmarkt-News senken Volatilität – Reaktion oft vorab eingepreist. |\n",
    "| `impact_max` | 0.15 | [-0.01; +0.32] | Grenzwertig positiv: einzelne „laute“ Meldungen wirken wohl. |\n",
    "| Weitere Aggregats- & Preis­features | – | CI überlappt 0 | Kein robuster Einfluss → möglicher Feature-Overload. |\n",
    "\n",
    "\n",
    "\n",
    "##### 3 ) Prognose­intervalle & Fehlerbild  \n",
    "\n",
    "*Plot-Beobachtungen*  \n",
    "- Blaue Fläche deckt die meisten Punkte → PIs sind brauchbar.  \n",
    "- Extreme Returns (≈ 1.5 – 1.8 %) liegen komplett außerhalb ⇒ Varianz nicht konstant (Heavy Tails).  \n",
    "- Vorhersage­linie glättet Peaks – typisch MSE-optimiertes lineares Modell.\n",
    "\n",
    "\n",
    "##### 4 ) TL;DR  \n",
    "\n",
    "- Modell erklärt **≈ 26 %** der 30-Min-Volatilität – solide für einen linearen Ansatz.  \n",
    "- Signifikanter Nutzen: **Vorperioden-Volatilität** & starke **Zins/Arbeitsmarkt-News**.  \n",
    "- **Generalisiert** ordentlich, überfit­tet nicht, wird aber durch Rauschen & fette Schwänze begrenzt.  \n",
    "- Mehr Power erfordert **nicht-lineare Modelle** und **bessere Fehler­modellierung**.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "## **6. Gewichtskonstruktion**\n",
    "\n",
    "Die Gewichte basieren auf dem einfachen Verhältnis\n",
    "\n",
    "**ρ = Mittelwert mit News / Mittelwert Baseline**\n",
    "\n",
    "für jede News-Kategorie.  \n",
    "Alle ρ-Werte sind positiv und können daher direkt als Gewichte in einer\n",
    "gewichteten linearen Regression verwendet werden.\n",
    "\n",
    "### Input-Daten und abgeleitete Gewichte\n",
    "\n",
    "| Kategorie           | Mittelwert mit News | Mittelwert Baseline | Gewicht ρ (News / Baseline) |\n",
    "|---------------------|--------------------:|--------------------:|----------------------------:|\n",
    "| politics            | 0.1612 | 0.1734 | 0.9296 |\n",
    "| interest_rate       | 0.6288 | 0.1734 | 3.6262 |\n",
    "| labor_market        | 0.3527 | 0.1734 | 2.0340 |\n",
    "| inflation           | 0.3594 | 0.1734 | 2.0726 |\n",
    "| central_banks       | 0.2886 | 0.1734 | 1.6643 |\n",
    "| economic_activity   | 0.2885 | 0.1734 | 1.6637 |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_map = {\n",
    "    \"politics\":          0.9296,\n",
    "    \"interest_rate\":     3.6262,\n",
    "    \"labor_market\":      2.0340,\n",
    "    \"inflation\":         2.0726,\n",
    "    \"central_banks\":     1.6643,\n",
    "    \"economic_activity\": 1.6637,\n",
    "}\n",
    "\n",
    "X[\"weighted_col\"] = X.apply(\n",
    "    lambda row: max([weight_map[c] for c in weight_map if row[f\"cat_{c}_event_count\"] > 0], default=0),\n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "## **7. Gewichtete Multiple Lineare Regression (MLR)**\n",
    "\n",
    "Es wird eine multiple lineare Regression auf die absolute Rendite (|Return|) durchgeführt, um Zusammenhänge zwischen den Features und der Zielgröße zu untersuchen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2, X_train2, X_test2, y_train2, y_test2 = mlr(\n",
    "    X, y_regression,\n",
    "    train_ratio=0.5,\n",
    "    random_state=42,\n",
    "    n_bootstrap=10_000,\n",
    "    ci=0.95,\n",
    "    weight=\"weighted_col\"\n",
    ")\n",
    "evaluate_regression(model2, X_train2, y_train2, X_test2, y_test2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "### Interpretation \n",
    "\n",
    "##### 0 ) Kurzüberblick  \n",
    "\n",
    "| Modell | Gewichtung | R² (Test) | RMSE (Test) | MAE (Test) |\n",
    "|--------|-----------|-----------|-------------|------------|\n",
    "| **Ungewichtet** | – | **0.258** | 0.206 | 0.140 |\n",
    "| **Gewichtet**   | ✓ | **0.255** | 0.206 | 0.141 |\n",
    "\n",
    "> **Take-away:** Die Gewichtung verändert die Gesamtgüte **kaum** – alle Fehler­metriken bleiben praktisch identisch.  \n",
    "\n",
    "##### 1 ) Güte der gewichteten Regression  \n",
    "\n",
    "| Kennzahl | Train | Test | Interpretation |\n",
    "|----------|------:|-----:|----------------|\n",
    "| **R²**   | 0.268 | 0.255 | ≈ 25 % erklärte Varianz – identisch zum ungewichteten Modell. |\n",
    "| **RMSE** | 0.208 | 0.206 | Fehlergröße weiterhin in derselben Größenordnung wie der Zielwert selbst. |\n",
    "| **MAE**  | 0.146 | 0.141 | Spiegelt RMSE-Befund; kein Overfitting sichtbar (Train≈Test). |\n",
    "\n",
    "##### 2 ) Feature-Effekte (Bootstrap-CIs, gewichtetes Modell)  \n",
    "\n",
    "| Feature (Auswahl) | β | 95 %-CI | Deutung |\n",
    "|-------------------|---:|:-------:|---------|\n",
    "| `\\|Return\\|_shifted1` | **0.27** | [+0.18; +0.37] | Volatility-Clustering; Effekt **größer** als im Basis-Modell (+0.25). |\n",
    "| `cat_interest_rate_event_count` | **0.011** | [+0.004; +0.018] | *Neu signifikant*: Schon die **Anzahl** von Zins-Meldungen treibt Volatilität. |\n",
    "| `cat_interest_rate_impact_sum` | **0.032** | [+0.011; +0.055] | Bleibt klar positiv; Gewichtung verstärkt den Effekt leicht. |\n",
    "| `impact_max` | 0.15 | [−0.02; +0.33] | Grenzwertig, ähnlich wie Basis-Modell. |\n",
    "| `cat_labor_market_impact_sum` | 0.018 | [−0.006; +0.045] | Nicht mehr signifikant (überlappt 0) – Gewichtung **schwächt** diesen Einfluss. |\n",
    "| `Volume_shifted` | ~0 | CI enthält 0 | Weiterhin vernachlässigbar. |\n",
    "| *Restliche Aggregats-/Preis-Features* | – | CI überlappt 0 | Kein robuster Einfluss – unverändert. |\n",
    "\n",
    "**Was hat sich geändert?**  \n",
    "- **Zinsrelevante Variablen** gewinnen an Bedeutung (Event-Count & Impact-Sum beide signifikant).  \n",
    "- **Arbeitsmarkt-Signale** verlieren Signifikanz.  \n",
    "- Gesamte Varianzaufklärung bleibt jedoch gleich – die Gewichtung verschiebt **relativ** die Wichtigkeit einzelner Prädiktoren, nicht aber die Gesamtleistung.\n",
    "\n",
    "##### 3 ) Prognoseintervalle & Fehlerbild  \n",
    "\n",
    "*Visualeinschätzung (identisch zu Basis-Plot)*  \n",
    "- 95 %-Intervalle decken die meisten tatsächlichen Werte ab.  \n",
    "- Die extremsten Returns (> 1.5 %) liegen weiterhin außerhalb ⇒ Heavy-Tail-Problem bleibt ungelöst.  \n",
    "- Keine sichtbare systematische Verzerrung durch die Gewichtung.\n",
    "\n",
    "##### 4 ) Interpretation des Gewichtungs­effekts  \n",
    "\n",
    "| Beobachtung | Mögliche Ursache |\n",
    "|-------------|------------------|\n",
    "| **Stabile Gesamtmetriken** | Gewicht scheinen v. a. Beobachtungen zu betreffen, die bereits im linearen Rahmen gut erklärbar sind; sie ändern nicht das inhärente Rausch-/Signal-Verhältnis. |\n",
    "| **Stärkere Zinssensitivität** | Gewichtung könnte Perioden mit makro-relevanten Bewegungen (z. B. FOMC-Tage) höher bewertet haben. |\n",
    "| **Abnehmende Arbeitsmarkt-Relevanz** | Entweder geringeres Gewicht auf NFP-Tage oder Überbetonung anderer Event-Typen. |\n",
    "\n",
    "##### 5 ) TL;DR  \n",
    "\n",
    "- **Leistungs­gleichstand**: Gewichtung ändert die Modellgüte **nicht** spürbar.  \n",
    "- **Signalverschiebung**: Zinsspezifische Features werden wichtiger, Arbeitsmarkt-Effekte schwächer.  \n",
    "- **Nächster Schritt**: Mehr Modellflexibilität & fokussierte Feature-Selektion, um den durch Gewichtung angedeuteten Informationsgewinn besser auszuschöpfen.  \n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "## **8. Naive Bayes Klassifikation**\n",
    "\n",
    "Im nächsten Schritt wird ein Naive Bayes Modell verwendet, um die Richtung der Kursbewegung (steigend/fallend) zu klassifizieren.\n",
    "\n",
    "Hier führen wir eine Klassifikation durch, ob der Kurs steigt oder fällt. Als Input werden alle verfügbaren Features genutzt.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_model, X_tr, X_te, y_tr, y_te = naive_bayes(\n",
    "    X, y_classification, train_ratio=0.7\n",
    ")\n",
    "evaluate_classification(nb_model, X_tr, y_tr, X_te, y_te)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "### Interpretation  \n",
    "\n",
    "##### 1 ) Performance-Übersicht  \n",
    "\n",
    "| Datensatz | Accuracy | Precision&nbsp;0 / 1 | Recall&nbsp;(Sensitivität)&nbsp;0 / 1 | F1-Score&nbsp;0 / 1 | Klassen­verhältnis |\n",
    "|-----------|---------:|----------------------|---------------------------------------|--------------------|--------------------|\n",
    "| **Train** | **0.53** | 0.53 / 0.54 | 0.49 / 0.58 | 0.51 / 0.55 | 1341 : 1380 |\n",
    "| **Test**  | **0.51** | 0.50 / 0.51 | 0.46 / 0.55 | 0.48 / 0.53 | 575 : 592 |\n",
    "\n",
    "**Relevanz (Precision)**  \n",
    "- Misst den Anteil der **korrekten positiven Vorhersagen** an allen „steigt“-Calls.  \n",
    "- Wert ~0.51 auf dem Test-Set ⇒ Von 100 Long-Signalen sind knapp 51 tatsächlich steigende Perioden ⇒ jede zweite Position wäre unnötig.  \n",
    "\n",
    "**Sensitivität (Recall)**  \n",
    "- Misst den Anteil der **erkannten positiven Fälle** an allen tatsächlich steigenden Perioden.  \n",
    "- Recall(1) = 0.55 ist höher als Recall(0) = 0.46 → Modell erkennt gut die Hälfte aller realen Anstiege, übersieht aber fast ebenso viele.  \n",
    "- Geringer Recall(0) bedeutet, dass fast **54 %** der echten Rückgänge als „steigt“ fehlklassifiziert werden – kritisch, wenn Short-Side-Risiken abgesichert werden sollen.  \n",
    "\n",
    "> **Gesamtbild:** Sowohl Relevanz als auch Sensitivität liegen knapp über dem Zufalls­niveau. Keines der beiden Qualitäts­kriterien ist in einem Trading-Kontext ausreichend, da Fehl­signale Transaktions­kosten und Drawdowns verursachen.\n",
    "\n",
    "##### 2 ) Confusion-Matrix-Einordnung  \n",
    "\n",
    "|                 | **Vorhergesagt 0** | **Vorhergesagt 1** |\n",
    "|-----------------|-------------------:|-------------------:|\n",
    "| **Tatsächlich 0** | 266 (Test) / 653 (Train) | 309 / 688 |\n",
    "| **Tatsächlich 1** | 268 / 586 | 324 / 794 |\n",
    "\n",
    "- **Fehler­symmetrie**: Falsch-Positiv- und Falsch-Negativ-Raten sind ähnlich hoch.  \n",
    "- **Bias Richtung 1**: Das Modell bevorzugt Long-Signale ⇒ Recall(1) > Recall(0).  \n",
    "\n",
    "##### 3 ) Warum performt Naive Bayes schwach?  \n",
    "\n",
    "1. **Unabhängigkeits­annahme verletzt** – News-Features, Volumen & Returns sind korreliert.  \n",
    "2. **Verteilungsform** – Gaussian-NB passt schlecht zu heavy-tailed Finanzdaten.  \n",
    "3. **Kurzes Prognosefenster (30 min)** – Grundrauschen dominiert, Signal-to-Noise extrem klein.  \n",
    "4. **Feature-Set** – identisch zur Regression; diskrete Schwellen oder Interaktionen fehlen.  \n",
    "\n",
    "##### 4 ) Handlungsempfehlungen  \n",
    "\n",
    "| Hebel | Idee |\n",
    "|-------|------|\n",
    "| **Baselines austauschen** | Regularisierte logistische Regression. |\n",
    "| **Nicht-lineare Modelle** | Gradient Boosting, Random Forest, SVM, MLP. |\n",
    "| **Feature Engineering** | Binning von Impact-Scores, Interaktion *Event-Typ × Impact*, Momentum-Indikatoren. |\n",
    "| **Kostensensitive Lernziele** | Verlustmatrix an Long/Short-Kosten anpassen, Entscheidungs­schwelle optimieren. |\n",
    "| **Kalibrierte Wahrscheinlichkeiten** | Platt/Isotonic Scaling, um Trades nur bei ≥ p* auszulösen. |\n",
    "\n",
    "##### 5 ) TL;DR  \n",
    "\n",
    "- **Accuracy & F1 ≈ 0.5** ⇒ Modell kaum besser als Münzwurf.  \n",
    "- **Relevanz ~ Sensitivität** zeigen, dass jedes zweite Signal falsch ist und gut die Hälfte der wahren Bewegungen verpasst wird.  \n",
    "- Kernprobleme: Naive-Bayes-Annahmen + geringes Richtungs­signal. Nicht-lineare Modelle und feature-reichere Repräsentationen sind nötig, um jenseits der 50-%-Schwelle zu kommen.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "## **9. Lineare Diskriminanzanalyse (LDA)**\n",
    "\n",
    "Hier wird eine LDA durchgeführt, um die Kursrichtung ebenfalls zu klassifizieren und die Ergebnisse mit dem Naive Bayes Modell zu vergleichen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model, X_tr2, X_te2, y_tr2, y_te2 = lda(\n",
    "    X, y_classification, train_ratio=0.7\n",
    ")\n",
    "evaluate_classification(lda_model, X_tr2, y_tr2, X_te2, y_te2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "### Interpretation  \n",
    "\n",
    "##### 1 ) Performance‐Übersicht  \n",
    "\n",
    "| Datensatz | Accuracy | Precision&nbsp;(Relevanz)&nbsp;0 / 1 | Recall&nbsp;(Sensitivität)&nbsp;0 / 1 | F1-Score&nbsp;0 / 1 | Klassen­verhältnis |\n",
    "|-----------|---------:|--------------------------------------|---------------------------------------|--------------------|--------------------|\n",
    "| **Train** | **0.55** | 0.55 / 0.55 | 0.46 / 0.62 | 0.50 / 0.58 | 1341 : 1380 |\n",
    "| **Test**  | **0.51** | 0.50 / 0.52 | 0.44 / 0.58 | 0.47 / 0.55 | 575 : 592 |\n",
    "\n",
    "###### Relevanz (Precision)  \n",
    "- **Class 0**: 0.50 → Von 100 „Fall“-Signalen sind nur 50 korrekt.  \n",
    "- **Class 1**: 0.52 → Etwas bessere Trefferquote für „Steigt“, aber jedes zweite Long-Signal bleibt Fehltrade.\n",
    "\n",
    "###### Sensitivität (Recall)  \n",
    "- **Class 1 (0.58)** > **Class 0 (0.44)**. LDA erkennt ~58 % aller realen Anstiege, lässt aber 42 % unentdeckt.  \n",
    "- Lediglich 44 % der tatsächlichen Rückgänge werden korrekt erkannt → Short-Chancen gehen oft verloren.\n",
    "\n",
    "> **Bottom line:** Trotz leichter Verbesserung auf dem Trainings-Set (Acc 55 %) liegt die **Test-Accuracy bei 51 %**, kaum höher als Zufall. Relevanz und Sensitivität verharren um die 0.5-Marke – für profitables Intraday-Trading unzureichend.\n",
    "\n",
    "##### 2 ) Confusion‐Matrix (Test-Set)  \n",
    "\n",
    "|                 | **Prädi­ziert 0** | **Prädi­ziert 1** |\n",
    "|-----------------|------------------:|------------------:|\n",
    "| **Tatsäch­lich 0** | **251** (True Neg) | **324** (False Pos) |\n",
    "| **Tatsäch­lich 1** | **247** (False Neg) | **345** (True Pos) |\n",
    "\n",
    "- **Bias zu Klasse 1**: Mehr False-Positives als False-Negatives → Modell tendiert zu Long-Calls.  \n",
    "- **Fehler­quote**: 571 von 1167 Beobachtungen sind Fehlklassifikationen (≈ 49 %).\n",
    "\n",
    "##### 3 ) Vergleich zu Naive Bayes  \n",
    "\n",
    "| Modell | Train-Acc | Test-Acc | Recall(1) | Hauptunterschied |\n",
    "|--------|----------:|---------:|-----------:|------------------|\n",
    "| **Naive Bayes** | 0.53 | 0.51 | 0.55 | Unabhängigkeits­annahme, Gaussian-Dichte |\n",
    "| **LDA** | **0.55** | 0.51 | **0.58** | Nutzt Kovarianzstruktur → etwas mehr „Steigt“ erkannt, aber Generalisierung nicht besser |\n",
    "\n",
    "> **Interpretation:** LDA eliminiert die starke Unabhängigkeits­annahme von NB und passt Mittelwert-Vektoren & gemeinsame Kovarianz an. Das bringt **+2 pp** Accuracy im Train-Set, **aber keinen Test-Gewinn** → Hinweis auf leichte Überanpassung und insgesamt schwaches Signal im Datensatz.\n",
    "\n",
    "##### 4 ) Warum bleibt die Leistung limitiert?  \n",
    "\n",
    "1. **Fast komplett überlappende Klassen** – 30-Min-Returns nähern sich einer zufälligen Binär­verteilung.  \n",
    "2. **Lineare Entscheidungsgrenze** – Falls die Trennung im Feature-Raum nicht linear ist, kann LDA sie nicht erfassen.  \n",
    "3. **Homoskedastizitätsannahme** – LDA nimmt gleiche Kovarianz­matrix für beide Klassen an; bei hetero­skedastischen Finanzdaten unrealistisch.  \n",
    "4. **Feature-Set** – Identisch zum Regressionsmodell; keine speziell auf Richtung optimierten Signale (Momentum-Vorzeichen, Schwellen­indikatoren …).\n",
    "\n",
    "##### 5 ) Handlungsempfehlungen  \n",
    "\n",
    "| Bereich | Maßnahme |\n",
    "|---------|----------|\n",
    "| **Modell** | Quadratische DA (QDA) zulassen, Gradient Boosting, XGBoost, Random Forest, SVM mit RBF-Kernel. |\n",
    "| **Regularisierung** | Shrinkage-LDA oder Ridge-Logit testen, um Varianz zu reduzieren. |\n",
    "| **Feature Engineering** | Diskretisiertes „Impact > x“-Flag, gleitende Vorzeichenwechsel, Interaktion *Event-Typ × Impact*. |\n",
    "| **Threshold-Tuning** | Statt fester 0.5-Schwelle kosten­sensitives ROC-/PR-Optimieren auf Sharpe Ratio oder Hit-Rate. |\n",
    "| **Ensemble** | Combine directional classifier with volatility filter (only trade when |predicted return| > k·σ). |\n",
    "\n",
    "##### 6 ) TL;DR  \n",
    "\n",
    "- **LDA** schlägt Naive Bayes im Train-Set, **nicht** im Test-Set (Acc bleibt 51 %).  \n",
    "- Leichter **Long-Bias**, Relevanz & Sensitivität um 0.5 – praktisch Münzwurf.  \n",
    "- Limitierende Faktoren: Lineare Trennbarkeit, homoskedastische Annahme, geringes Richtungs­signal.  \n",
    "- **Nicht-lineare, regularisierte oder ensemble-basierte Ansätze** + gezieltes Feature-Engineering sind nötig, um die 50 %-Barriere zu überwinden.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {},
   "source": [
    "## **10. Logistische Regression**\n",
    "\n",
    "Hier wird eine LDA durchgeführt, um die Kursrichtung ebenfalls zu klassifizieren und die Ergebnisse mit dem Naive Bayes Modell zu vergleichen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_model, X_tr3, X_te3, y_tr3, y_te3 = logistic_regression_classifier(\n",
    "    X,                      \n",
    "    y_classification,        \n",
    "    train_ratio=0.7         \n",
    ")\n",
    "\n",
    "evaluate_classification(logreg_model, X_tr3, y_tr3, X_te3, y_te3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {},
   "source": [
    "### Logistische Regression – Interpretation  \n",
    "\n",
    "##### 1 ) Performance-Übersicht  \n",
    "\n",
    "| Datensatz | Accuracy | Precision (Relevanz) 0 / 1 | Recall (Sensitivität) 0 / 1 | F1-Score 0 / 1 | Klassen­verhältnis |\n",
    "|-----------|---------:|---------------------------|-----------------------------|-----------------|--------------------|\n",
    "| **Train** | **0.53** | 0.53 / 0.53 | 0.42 / 0.65 | 0.47 / 0.59 | 1341 : 1380 |\n",
    "| **Test**  | **0.54** | 0.54 / 0.54 | 0.43 / 0.64 | 0.48 / 0.58 | 575 : 592 |\n",
    "\n",
    "**Relevanz (Precision)**  \n",
    "- *Class 0* = 0.54 → Nur 54 % der „Fall“-Signale korrekt.  \n",
    "- *Class 1* = 0.54 → Gleich hohe Treffer­quote für „Steigt“.  \n",
    "\n",
    "**Sensitivität (Recall)**  \n",
    "- *Class 1* = 0.64 → Modell findet knapp zwei Drittel aller realen Anstiege.  \n",
    "- *Class 0* = 0.43 → Erkennt weniger als die Hälfte der tatsächlichen Rückgänge.  \n",
    "\n",
    "> **Gesamtbild:** Mit **54 % Accuracy** schlägt die logistische Regression Naive Bayes und LDA um ~3 Prozentpunkte, bleibt aber nur knapp über Zufall.\n",
    "\n",
    "\n",
    "##### 2 ) Confusion-Matrix (Test)  \n",
    "\n",
    "|                 | **Pred 0** | **Pred 1** |\n",
    "|-----------------|-----------:|-----------:|\n",
    "| **True 0**      | **249**    | **326** |\n",
    "| **True 1**      | **216**    | **376** |\n",
    "\n",
    "- **Long-Bias:** 326 False-Positives vs. 216 False-Negatives → Modell tendiert zu Long-Calls.  \n",
    "- **Fehler­rate:** 542 von 1167 Beobachtungen sind Fehl­klassifikationen (≈ 46 %).  \n",
    "\n",
    "\n",
    "##### 3 ) Vergleich zu bisherigen Modellen  \n",
    "\n",
    "| Modell | Test-Accuracy | Recall(1) | Recall(0) | Haupteindruck |\n",
    "|--------|--------------:|----------:|----------:|---------------|\n",
    "| Naive Bayes | 0.51 | 0.55 | 0.46 | Fast Zufall, starke Annahme­verletzungen |\n",
    "| LDA | 0.51 | 0.58 | 0.44 | Linear, homoskedastisch, kaum Generalisierung + |\n",
    "| **Logit** | **0.54** | **0.64** | 0.43 | Beste Recall (1), aber niedrige Recall (0); leichter Fortschritt |\n",
    "\n",
    "> **Interpretation:** Die regularisierte logistische Regression profitiert davon, Feature-Korrelationen zuzulassen und eine probabilistische Schwelle zu optimieren. Dennoch bleibt das Richtungs­signal schwach.\n",
    "\n",
    "\n",
    "##### 4 ) Warum bremst die Performance?  \n",
    "\n",
    "1. **Klassenüberlappung:** Steigen/Fallen in 30 min ist größtenteils zufällig – Signal-to-Noise gering.  \n",
    "2. **Lineare Entscheidungs­grenze:** Logit erfasst keine nicht-linearen Interaktionen zwischen News-Impact und Markt­zustand.  \n",
    "3. **Asymmetrische Kosten nicht berücksichtigt:** Falsche Long-Signale (FP) können teuer sein, werden hier gleich gewichtet.  \n",
    "4. **Unverändertes Feature-Set:** Noch immer rein numerische Aggregationen; keine Schwellen- oder Richtungs­­indikatoren.  \n",
    "\n",
    "\n",
    "##### 5 ) Handlungsempfehlungen  \n",
    "\n",
    "| Bereich | Maßnahme |\n",
    "|---------|----------|\n",
    "| **Schwellen­optimierung** | ROC/PR-Kurven analysieren, Schwelle > 0.5 an Kosten/Nutzen anpassen. |\n",
    "| **Nicht-lineare Modelle** | Gradient Boosting (XGBoost, LightGBM), Random Forest, SVM-RBF, MLP. |\n",
    "| **Feature Engineering** | Diskrete Flags (Impact > x), Momentum-Vorzeichen, Interaktion *Event-Typ × Impact*, Intraday-Seasonality. |\n",
    "| **Kostensensitives Lernen** | Custom Loss, Gewichtung FP vs. FN entsprechend Handels­strategie. |\n",
    "| **Ensembles/Stacking** | Kombinieren von Logit-Wahrscheinlichkeiten mit Volatilitäts-Regressor → nur traden, wenn |pred_return| über Schwellwert liegt. |\n",
    "\n",
    "\n",
    "\n",
    "##### 6 ) TL;DR  \n",
    "\n",
    "- **Logistische Regression verbessert Accuracy auf 54 %** – bestes Ergebnis der drei Grundlagen­modelle, aber weiterhin nur knapp über Münzwurf.  \n",
    "- **Recall (1) = 0.64** → erkennt die Mehrzahl der Anstiege, übersieht jedoch viele Rückgänge und produziert viele Long-Fehltrades.  \n",
    "- **Linearität & Feat**\n",
    "\n",
    "---\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
